{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Logistic Regression in scikit-learn - Lab\n","\n","## Introduction \n","\n","In this lab, you are going to fit a logistic regression model to a dataset concerning heart disease. Whether or not a patient has heart disease is indicated in the column labeled `'target'`. 1 is for positive for heart disease while 0 indicates no heart disease.\n","\n","## Objectives\n","\n","In this lab you will: \n","\n","- Fit a logistic regression model using scikit-learn \n","\n","\n","## Let's get started!\n","\n","Run the following cells that import the necessary functions and import the dataset: "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import necessary functions\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>63</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>145</td>\n","      <td>233</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>2.3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>250</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>187</td>\n","      <td>0</td>\n","      <td>3.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>204</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>1.4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>236</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>178</td>\n","      <td>0</td>\n","      <td>0.8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>354</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>1</td>\n","      <td>0.6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n","0   63    1   3       145   233    1        0      150      0      2.3      0   \n","1   37    1   2       130   250    0        1      187      0      3.5      0   \n","2   41    0   1       130   204    0        0      172      0      1.4      2   \n","3   56    1   1       120   236    0        1      178      0      0.8      2   \n","4   57    0   0       120   354    0        1      163      1      0.6      2   \n","\n","   ca  thal  target  \n","0   0     1       1  \n","1   0     2       1  \n","2   0     2       1  \n","3   0     2       1  \n","4   0     2       1  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Import data\n","df = pd.read_csv('heart.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Define appropriate `X` and `y` \n","\n","Recall the dataset contains information about whether or not a patient has heart disease and is indicated in the column labeled `'target'`. With that, define appropriate `X` (predictors) and `y` (target) in order to model whether or not a patient has heart disease."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Split the data into target and predictors\n","y = df[\"target\"] #dependent variable\n","X = df.drop(columns=\"target\",axis = 1) #independent variables"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.60416667, 1.        , 0.66666667, ..., 1.        , 0.5       ,\n","        1.        ],\n","       [0.47916667, 1.        , 0.        , ..., 1.        , 0.25      ,\n","        0.66666667],\n","       [0.52083333, 1.        , 0.66666667, ..., 1.        , 0.        ,\n","        1.        ],\n","       ...,\n","       [0.5625    , 1.        , 1.        , ..., 0.5       , 0.        ,\n","        1.        ],\n","       [0.375     , 1.        , 0.66666667, ..., 1.        , 0.        ,\n","        0.66666667],\n","       [0.60416667, 1.        , 0.33333333, ..., 0.5       , 0.        ,\n","        0.66666667]])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["X"]},{"cell_type":"markdown","metadata":{},"source":["## Train- test split \n","\n","- Split the data into training and test sets \n","- Assign 25% to the test set \n","- Set the `random_state` to 0 \n","\n","N.B. To avoid possible data leakage, it is best to split the data first, and then normalize."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=0)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>173</th>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>132</td>\n","      <td>224</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>173</td>\n","      <td>0</td>\n","      <td>3.2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>261</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>112</td>\n","      <td>230</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>160</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>54</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>150</td>\n","      <td>232</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>165</td>\n","      <td>0</td>\n","      <td>1.6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>178</td>\n","      <td>270</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>145</td>\n","      <td>0</td>\n","      <td>4.2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>166</th>\n","      <td>67</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>229</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>129</td>\n","      <td>1</td>\n","      <td>2.6</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>251</th>\n","      <td>43</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>132</td>\n","      <td>247</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>143</td>\n","      <td>1</td>\n","      <td>0.1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>192</th>\n","      <td>54</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>188</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>113</td>\n","      <td>0</td>\n","      <td>1.4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>120</td>\n","      <td>193</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>162</td>\n","      <td>0</td>\n","      <td>1.9</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>47</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>138</td>\n","      <td>257</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>156</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>172</th>\n","      <td>58</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>284</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>160</td>\n","      <td>0</td>\n","      <td>1.8</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>227 rows Ã— 13 columns</p>\n","</div>"],"text/plain":["     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n","173   58    1   2       132   224    0        0      173      0      3.2   \n","261   52    1   0       112   230    0        1      160      0      0.0   \n","37    54    1   2       150   232    0        0      165      0      1.6   \n","101   59    1   3       178   270    0        0      145      0      4.2   \n","166   67    1   0       120   229    0        0      129      1      2.6   \n","..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n","251   43    1   0       132   247    1        0      143      1      0.1   \n","192   54    1   0       120   188    0        1      113      0      1.4   \n","117   56    1   3       120   193    0        0      162      0      1.9   \n","47    47    1   2       138   257    0        0      156      0      0.0   \n","172   58    1   1       120   284    0        0      160      0      1.8   \n","\n","     slope  ca  thal  \n","173      2   2     3  \n","261      2   1     2  \n","37       2   0     3  \n","101      0   0     3  \n","166      1   2     3  \n","..     ...  ..   ...  \n","251      1   4     3  \n","192      1   1     3  \n","117      1   0     3  \n","47       2   0     2  \n","172      1   0     2  \n","\n","[227 rows x 13 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["X_train"]},{"cell_type":"markdown","metadata":{},"source":["## Normalize the data \n","\n","Normalize the data (`X`) prior to fitting the model. "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.60416667 1.         0.66666667 0.3877551  0.2147806  0.\n","  0.         0.77862595 0.         0.51612903 1.         0.5\n","  1.        ]\n"," [0.47916667 1.         0.         0.18367347 0.22863741 0.\n","  0.5        0.67938931 0.         0.         1.         0.25\n","  0.66666667]\n"," [0.52083333 1.         0.66666667 0.57142857 0.23325635 0.\n","  0.         0.71755725 0.         0.25806452 1.         0.\n","  1.        ]\n"," [0.625      1.         1.         0.85714286 0.32101617 0.\n","  0.         0.5648855  0.         0.67741935 0.         0.\n","  1.        ]\n"," [0.79166667 1.         0.         0.26530612 0.22632794 0.\n","  0.         0.44274809 1.         0.41935484 0.5        0.5\n","  1.        ]]\n"]}],"source":["# Your code here\n","from sklearn.preprocessing import MinMaxScaler\n","#initialize the scaler\n","scaler = MinMaxScaler()\n","#fit and transform the data\n","X = scaler.fit_transform(X)\n","#print the first few rows of the numpy array\n","print(X[:5])"]},{"cell_type":"markdown","metadata":{},"source":["## Fit a model\n","\n","- Instantiate `LogisticRegression`\n","  - Make sure you don't include the intercept  \n","  - set `C` to a very large number such as `1e12` \n","  - Use the `'liblinear'` solver \n","- Fit the model to the training data "]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# Instantiate the model\n","logreg = LogisticRegression(C=1e12, #large c value to minimize regularization\n","              solver=\"liblinear\", #solver  suited for small datasets\n","              fit_intercept=False #do not include intercept\n",")\n","#fit the model using the training data\n","model = logreg.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Coefficients: [[ 0.01744926 -2.0240387   0.89735576 -0.00646124 -0.00571495 -0.6343676\n","   0.26011902  0.03207797 -0.87141645 -0.58176784  0.29185079 -0.83375485\n","  -0.79652164]]\n"]}],"source":["#optionally print the coefficients\n","print(\"Coefficients:\",model.coef_)"]},{"cell_type":"markdown","metadata":{},"source":["## Predict\n","Generate predictions for the training and test sets. "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set predictions: [0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0\n"," 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0\n"," 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0\n"," 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1\n"," 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0\n"," 0 0 1 1 1]\n","Test set predictions: [0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n"," 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n"," 0 1]\n"]}],"source":["# Generate predictions\n","y_hat_train = model.predict(X_train)\n","y_hat_test = model.predict(X_test)\n","\n","print(\"Training set predictions:\",y_hat_train)\n","print(\"Test set predictions:\",y_hat_test)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set accuracy: 0.8546255506607929\n","Test set accuracy: 0.8289473684210527\n"]}],"source":["from sklearn.metrics import accuracy_score,classification_report\n","#Evaluating performance\n","print(\"Training set accuracy:\", accuracy_score(y_train, y_hat_train))\n","print(\"Test set accuracy:\", accuracy_score(y_test, y_hat_test))"]},{"cell_type":"markdown","metadata":{},"source":["## How many times was the classifier correct on the training set?"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.80      0.84       105\n","           1       0.84      0.90      0.87       122\n","\n","    accuracy                           0.85       227\n","   macro avg       0.86      0.85      0.85       227\n","weighted avg       0.86      0.85      0.85       227\n","\n"]}],"source":["# Your code here\n","#classification report for the training set\n","print(classification_report(y_train,y_hat_train))\n"]},{"cell_type":"markdown","metadata":{},"source":["## How many times was the classifier correct on the test set?"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.86      0.73      0.79        33\n","           1       0.81      0.91      0.86        43\n","\n","    accuracy                           0.83        76\n","   macro avg       0.83      0.82      0.82        76\n","weighted avg       0.83      0.83      0.83        76\n","\n"]}],"source":["# Your code here\n","#classification report on the test set\n","print(classification_report(y_test,y_hat_test))\n"]},{"cell_type":"markdown","metadata":{},"source":["## Analysis\n","Describe how well you think this initial model is performing based on the training and test performance. Within your description, make note of how you evaluated performance as compared to your previous work with regression."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your analysis here"]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","In this lab, you practiced a standard data science pipeline: importing data, split it into training and test sets, and fit a logistic regression model. In the upcoming labs and lessons, you'll continue to investigate how to analyze and tune these models for various scenarios."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":2}
